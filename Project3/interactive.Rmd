---
title: 'Data Analytics Project 3: Cancer Mortality Rate'
author: "Ananya Kaushik, Natasha Pirani, Nolan Bentley, and Juan Ramos Fuentes"
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
require(MASS)
require(ISLR)
require(ggplot2)
require(data.world)
require(plotly)
require(dplyr)
require(leaps)
require(tidyverse)
require(shiny)
knitr::opts_chunk$set(echo = TRUE)
```

## **Setting Up the Environment**  
### **R Session Info**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
sessionInfo()
```

### **Github Link**
https://github.com/jdramosf/cs329eda

### **data.world Project Link**
https://data.world/jdramosf/f-17-eda-project-3

### **Connecting to data.world**
```{r, echo=FALSE, message=FALSE, warning=FALSE}
source("data.R", echo = FALSE)
```

## **Introduction** 
This document contains an analysis on the cancer mortality rates per county in the USA 

### **Dataset -  Cancer Mortality Rate**
```{r, warning=FALSE}
#source("analysis.R", echo = FALSE)
renderDataTable( options = list(pageLength = 10), {
  cancer
})
```

## **Statistical Analysis**
### **Logistic Regression**
Throughout this analysis, we want to accurately predict the probability of an individual defaulting on their credit card payments. Because the variable we want to predict, *default*, is categorical, our first model is logistic regression.
We first want to see what the data looks like. Here we can see that slightly over 22% of individuals defaulted on their payments. This number will be important later on when we predict using our models. We also start by looking at the variable *sex* as one of our potential predictors.




###**Simple and Multiple Linear regression**

```{r, warning=FALSE}
plot_ly(data = cancer, x = ~medianage, y = ~target_deathrate)
medianage_nooutliers = medianage[medianage < 100]
deathrate_nooutliers = cancer$target_deathrate[medianage < 100]
plot_ly(data = cancer, x = ~medianage_nooutliers, y = ~deathrate_nooutliers)

# Creating a linear regression model, using medianage and adding other variables as we see fit
medagelm = lm(target_deathrate ~ medianage, data = cancer)
summary(medagelm)
# With a p-value of 0.8 for the medianage coefficient, we fail to reject the null hypothesis
# There is no relationship between median age and cancer death rate
# Let's add other variables
plot(target_deathrate ~ medincome, data = cancer)
medincomelm = lm(target_deathrate ~ medincome, data = cancer)
summary(medincomelm)
abline(medincomelm, col = "red")
# There seems to be some relationship between median income and cancer death rate, a negative relationship to be precise
# However, the R-squared value is too low (0.18), which means that our model does not fully explain the variance in the output variable
# This means that a multi-predictor linear model could be more accurate.

# Let's fit a linear model with more than one predictor
summary(cancer)
# Let's select predictors based on our own intuition. We believe that incidence rate, median income, population estimate, poverty percentage, unemployment percetange, and private coverage percentage could be the strongest predictors. Let's look at the relationships between these variables
multipred = cancer %>% dplyr::select(target_deathrate, incidencerate, medincome, popest2015, povertypercent, pctunemployed16_over, pctprivatecoverage)
pairs(multipred)
# (Some interesting relationships in this plot. We will explore some of these relationships in following insights)
multipredlm = lm(target_deathrate ~ ., data = multipred)
summary(multipredlm)
# We see some great results from this model! Aside from povertypercent, all of our predictors are statistically significant, and our R-squared has improved substantially (0.4284)
# This is a great start, but can we do better? We will look at better ways of identifying predictors for our model.
```

###**Model Selection - Best Subset Regression**
```{r, warning=FALSE}
subsetpred = cancer %>% dplyr::select(-binnedinc, -medianagefemale, -medianagemale, -geography, -pcths18_24, -pctnohs18_24, -pctsomecol18_24, -pctbachdeg18_24, -pctemployed16_over, -pctprivatecoveragealone, -pctempprivcoverage, -pctpubliccoverage, -pctpubliccoveragealone)
subsetpredsubm = regsubsets(target_deathrate ~ ., data = subsetpred, really.big = T, nvmax = 20)
summary(subsetpredsubm)
subsetpredsum = summary(subsetpredsubm)
names(subsetpredsum)
plot(subsetpredsum$cp,xlab="Number of Variables",ylab="Cp")
which.min(subsetpredsum$cp)
points(16,subsetpredsum$cp[16],pch=20,col="red")
plot(subsetpredsubm, scale = "Cp")
coef(subsetpredsubm, 16)
```

###**Forward Stepwise Selection**
```{r, warning=FALSE}
subsetpredsubm.fwd = regsubsets(target_deathrate ~ ., data = subsetpred, nvmax = 20,method = "forward")
summary(subsetpredsubm.fwd)
plot(subsetpredsubm.fwd, scale="Cp")
# Adding a validation set
dim(subsetpred)
set.seed(1)
train = sample(seq(3047), 2132, replace=FALSE)
regfit.fwd=regsubsets(target_deathrate ~ ., data = subsetpred[train,], nvmax = 20, method = "forward")
# Predicting on test set
val.errors = rep(NA, 20)
x.test = model.matrix(target_deathrate ~ ., data = subsetpred[-train,])
for(i in 1:20){ 
  coefi = coef(regfit.fwd, id = i)
  pred = x.test[,names(coefi)]%*%coefi
  val.errors[i] = mean((subsetpred$target_deathrate[-train] - pred) ^ 2)
}
plot(sqrt(val.errors), ylab="Root MSE", ylim = c(19, 25), pch = 20, type = "b")
points(sqrt(regfit.fwd$rss[-1]/2132),col="blue",pch=20,type="b")
legend("topright",legend=c("Training","Validation"),col=c("blue","black"),pch=20)
```




**LDA**
Confusion matrices and overall accuracy



